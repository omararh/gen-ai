{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Qu'est ce que le \"prompt caching\" ?\n",
    "Il permet de stocker puis de rÃ©utiliser les rÃ©ponses gÃ©nÃ©rÃ©es par les invites exÃ©cutÃ©es lors de l'utilisation de modÃ¨les de langage.\n",
    "\n",
    "Ici, nous allons utiliser Redis pour stocker les questions et rÃ©ponses. Nous mettrons en place une recherche sÃ©mantique sur les donnÃ©es enregistrÃ©es, et si le rÃ©sultat dÃ©passe un certain seuil de similaritÃ©, nous retournerons directement la rÃ©ponse stockÃ©e au lieu de faire un nouvel appel API au modÃ¨le de langage (LLM).\n",
    "\n",
    "\n"
   ],
   "id": "18853d16b96292e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install redis\n",
    "# docker run -d -p 6379:6379 redis"
   ],
   "id": "5f2666a1782e90b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T12:53:07.291560Z",
     "start_time": "2025-09-27T12:53:07.277256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setting up redis connection\n",
    "import redis\n",
    "\n",
    "REDIS_URL = \"redis://localhost:6379\"\n",
    "redis_client = redis.from_url(REDIS_URL)\n",
    "redis_client.ping()"
   ],
   "id": "bc9c3b58252bfe01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:51:43.823076Z",
     "start_time": "2025-09-22T19:51:43.213078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# needed dependencies for `prompt` & `prompt caching`\n",
    "!pip install langchain-redis langchain_huggingface langchain-mistralai"
   ],
   "id": "97bc2136735c7181",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_redis import RedisSemanticCache\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"Qwen/Qwen3-Embedding-0.6B\")\n",
    "\n",
    "set_llm_cache(\n",
    "    RedisSemanticCache(redis_url=REDIS_URL, embeddings=embeddings_model)\n",
    ")"
   ],
   "id": "ea91aed9d0395db8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T13:18:07.542630Z",
     "start_time": "2025-09-27T13:17:51.110495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import getpass\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "MISTRAL_APIKEY = getpass.getpass(\"Please enter your Mistral API key (hit enter): \")\n",
    "llm = ChatMistralAI(model=\"mistral-small-latest\", mistral_api_key=MISTRAL_APIKEY)"
   ],
   "id": "eb47af929cfee8b2",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install --upgrade langchain-community",
   "id": "6ab52f616e226273",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T13:20:26.657965Z",
     "start_time": "2025-09-27T13:20:24.480458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "def execute_with_timing(prompt):\n",
    "    start_time = time.time()\n",
    "    result = llm.invoke(prompt)\n",
    "    end_time = time.time()\n",
    "    return result, end_time - start_time\n",
    "\n",
    "# Original prompt (in French)\n",
    "original_prompt = \"What is the capital of France?\"\n",
    "result1, time1 = execute_with_timing(original_prompt)\n",
    "print(f\"Original query:\\nPrompt: {original_prompt}\\n\")\n",
    "print(f\"{result1}\\nTime: {time1:.2f} seconds\\n\")\n",
    "\n",
    "# Semantically similar prompt (in English)\n",
    "similar_prompt = \"Can you tell me the capital city of France?\"\n",
    "result2, time2 = execute_with_timing(similar_prompt)\n",
    "print(f\"Similar query:\\nPrompt: {similar_prompt}\\n\")\n",
    "print(f\"{result2}\\nTime: {time2:.2f} seconds\\n\")\n",
    "\n",
    "print(f\"Speed improvement: {time1 / time2:.2f}x faster\")"
   ],
   "id": "451a2a16de562ef7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:20:26 httpx INFO   HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Original query:\n",
      "Prompt: What is the capital of France?\n",
      "\n",
      "content='The capital of France is **Paris**.\\n\\nIt is one of the most famous and visited cities in the world, known for its iconic landmarks such as the **Eiffel Tower**, **Louvre Museum**, and **Notre-Dame Cathedral**. Paris is also a major cultural, economic, and political center in Europe.\\n\\nWould you like to know more about Paris or France in general? ðŸ˜Š' additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 10, 'total_tokens': 91, 'completion_tokens': 81}, 'model_name': 'mistral-small-latest', 'model': 'mistral-small-latest', 'finish_reason': 'stop'} id='run--2d03855d-fb2a-4aca-aaeb-550af1da81df-0' usage_metadata={'input_tokens': 10, 'output_tokens': 81, 'total_tokens': 91}\n",
      "Time: 2.07 seconds\n",
      "\n",
      "Similar query:\n",
      "Prompt: Can you tell me the capital city of France?\n",
      "\n",
      "content='The capital of France is **Paris**.\\n\\nIt is one of the most famous and visited cities in the world, known for its iconic landmarks such as the **Eiffel Tower**, **Louvre Museum**, and **Notre-Dame Cathedral**. Paris is also a major cultural, economic, and political center in Europe.\\n\\nWould you like to know more about Paris or France in general? ðŸ˜Š' additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 10, 'total_tokens': 91, 'completion_tokens': 81}, 'model_name': 'mistral-small-latest', 'model': 'mistral-small-latest', 'finish_reason': 'stop'} id='run--2d03855d-fb2a-4aca-aaeb-550af1da81df-0' usage_metadata={'input_tokens': 10, 'output_tokens': 81, 'total_tokens': 91, 'total_cost': 0}\n",
      "Time: 0.10 seconds\n",
      "\n",
      "Speed improvement: 21.10x faster\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "66d959e8609c81dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
